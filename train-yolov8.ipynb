{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T10:21:41.128130Z",
     "start_time": "2025-07-02T10:21:41.124838Z"
    }
   },
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:21:45.251795Z",
     "start_time": "2025-07-02T10:21:45.186126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from keras_cv.bounding_box import convert_format\n",
    "\n",
    "def build_dataset(image_dir, label_dir, batch_size=4, res_scale=1.0, target_format=\"xywh\"):\n",
    "    imgw = int(1920 * res_scale)\n",
    "    imgh = int(1080 * res_scale)\n",
    "\n",
    "    def parse_example(image_path):\n",
    "        image_path = image_path.numpy().decode(\"utf-8\")\n",
    "        label_path = image_path.replace(image_dir, label_dir).replace(\".png\", \".txt\")\n",
    "\n",
    "        # Load and decode image\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_png(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)  # normalize to [0, 1]\n",
    "\n",
    "        # Resize if needed\n",
    "        if res_scale != 1.0:\n",
    "            img = tf.image.resize(img, (imgh, imgw))  # TensorFlow uses (height, width)\n",
    "\n",
    "        # Read YOLO label file\n",
    "        boxes = []\n",
    "        classes = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                cls, x_c, y_c, w, h = map(float, line.strip().split())\n",
    "                boxes.append([x_c, y_c, w, h])  # YOLO format: rel_xywh\n",
    "                classes.append(int(cls))\n",
    "\n",
    "        # Convert to tensor\n",
    "        boxes = tf.convert_to_tensor(boxes, dtype=tf.float32)\n",
    "        classes = tf.convert_to_tensor(classes, dtype=tf.int32)\n",
    "\n",
    "        # Convert bounding boxes to desired format (e.g. \"xywh\")\n",
    "        boxes = convert_format(\n",
    "            boxes={\n",
    "                \"boxes\": boxes,\n",
    "                \"classes\": classes\n",
    "            },\n",
    "            source=\"rel_xywh\",\n",
    "            target=target_format,\n",
    "            images=img\n",
    "        )[\"boxes\"]\n",
    "\n",
    "        return img.numpy(), boxes.numpy(), classes.numpy()\n",
    "\n",
    "    def tf_parse_example(image_path):\n",
    "        img, boxes, classes = tf.py_function(parse_example, [image_path], [tf.float32, tf.float32, tf.int32])\n",
    "        img.set_shape((imgh, imgw, 3))\n",
    "        boxes.set_shape((None, 4))\n",
    "        classes.set_shape((None,))\n",
    "        return {\n",
    "            \"images\": img,\n",
    "            \"bounding_boxes\": {\n",
    "                \"classes\": classes,\n",
    "                \"boxes\": boxes\n",
    "            }\n",
    "        }\n",
    "\n",
    "    image_paths = tf.data.Dataset.list_files(image_dir + \"/*.png\", shuffle=True)\n",
    "    dataset = image_paths.map(tf_parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Usage:\n",
    "train_ds = build_dataset(\n",
    "    image_dir=\"./ds/images/train\",\n",
    "    label_dir=\"./ds/labels/train\",\n",
    "    res_scale=2,\n",
    ")\n",
    "\n",
    "test_ds = build_dataset(\n",
    "    image_dir=\"./ds/images/test\",\n",
    "    label_dir=\"./ds/labels/test\",\n",
    "    res_scale=2\n",
    ")\n"
   ],
   "id": "f9c59783f0673185",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:21:57.249189Z",
     "start_time": "2025-07-02T10:21:48.051896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras_cv.visualization import plot_bounding_box_gallery\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "e = next(iter(train_ds.take(1)))\n",
    "\n",
    "plot_bounding_box_gallery(e['images'], y_true=e['bounding_boxes'], value_range=(0, 255), bounding_box_format = \"xywh\")\n"
   ],
   "id": "9ed3948444d83638",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 11:21:49.864595: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 398131280 bytes after encountering the first element of size 398131280 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkeras_cv\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvisualization\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m plot_bounding_box_gallery\n\u001B[32m      4\u001B[39m e = \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(train_ds.take(\u001B[32m1\u001B[39m)))\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[43mplot_bounding_box_gallery\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mimages\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m=\u001B[49m\u001B[43me\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mbounding_boxes\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue_range\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m255\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounding_box_format\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mxywh\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/College/Practicum/ds/.venv2/lib/python3.11/site-packages/keras_cv/src/visualization/plot_bounding_box_gallery.py:177\u001B[39m, in \u001B[36mplot_bounding_box_gallery\u001B[39m\u001B[34m(images, value_range, bounding_box_format, y_true, y_pred, true_color, pred_color, line_thickness, font_scale, text_thickness, class_mapping, ground_truth_mapping, prediction_mapping, legend, legend_handles, rows, cols, **kwargs)\u001B[39m\n\u001B[32m    162\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    163\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mOnly pass `legend` OR `legend_handles` to \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    164\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m`luketils.visualization.plot_bounding_box_gallery()`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    165\u001B[39m         )\n\u001B[32m    166\u001B[39m     legend_handles = [\n\u001B[32m    167\u001B[39m         patches.Patch(\n\u001B[32m    168\u001B[39m             color=np.array(true_color) / \u001B[32m255.0\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    174\u001B[39m         ),\n\u001B[32m    175\u001B[39m     ]\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mplot_image_gallery\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplotted_images\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalue_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlegend_handles\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlegend_handles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    184\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/College/Practicum/ds/.venv2/lib/python3.11/site-packages/keras_cv/src/visualization/plot_image_gallery.py:174\u001B[39m, in \u001B[36mplot_image_gallery\u001B[39m\u001B[34m(images, value_range, scale, rows, cols, path, show, transparent, dpi, legend_handles)\u001B[39m\n\u001B[32m    170\u001B[39m index = row * cols + col\n\u001B[32m    171\u001B[39m current_axis = (\n\u001B[32m    172\u001B[39m     axes[row, col] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(axes, np.ndarray) \u001B[38;5;28;01melse\u001B[39;00m axes\n\u001B[32m    173\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m174\u001B[39m current_axis.imshow(\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m.astype(\u001B[33m\"\u001B[39m\u001B[33muint8\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m    175\u001B[39m current_axis.margins(x=\u001B[32m0\u001B[39m, y=\u001B[32m0\u001B[39m)\n\u001B[32m    176\u001B[39m current_axis.axis(\u001B[33m\"\u001B[39m\u001B[33moff\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mIndexError\u001B[39m: index 3 is out of bounds for axis 0 with size 3"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
